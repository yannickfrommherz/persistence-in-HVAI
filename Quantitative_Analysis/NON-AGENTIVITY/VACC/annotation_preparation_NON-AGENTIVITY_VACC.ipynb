{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc969cf-9fea-4d45-bca3-05b486c18b9a",
   "metadata": {},
   "source": [
    "# Non-Agentivity / VACC\n",
    "\n",
    "In this notebook, the preprocessed VACC corpus is annotated for the non-agentivity alternation, i.e., all alternating instances of passive voice constructions with \"werden\" and the impersonal pronoun \"man\" are tagged in the data. Subsequently, a dataset is prepared for modelling, i.e., all relevant variables (e.g., which variant was used in the previous slot?) from the tagged choice contexts are extracted or calculated. The resulting dataset is then combined with the data for the other two corpora and prepared for modelling in \"non-agentivity_all_corpora.ipynb\".\n",
    "\n",
    "As mentioned, the actual data used in the doctoral thesis needs to be requested from Ingo Siegert and subsequently preprocessed using the \"VACC\" notebook in the corresponding folder. \n",
    "\n",
    "However, the dummy dataset provided for the \"VACC\" notebook generates a dataset that can also be used to execute this very notebook. Note though that there are no instances of non-agentivity in the dummy dataset (have a look at the DEZEMBER alternation instead).\n",
    "\n",
    "Refer to the relevant chapter in the doctoral thesis for further explanation of the steps below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13db1e6-4e76-49d4-88e7-7a6481bfbada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant modules\n",
    "import pandas as pd, sys, os, shutil\n",
    "\n",
    "#informing Python about a custom code directory and importing some of the modules from there\n",
    "sys.path.append(\"../../../Code/\")\n",
    "import annotation, quantification, persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad403892-642e-401e-90c4-9b368cc20fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining name of the alternation set and establishing its variants\n",
    "alternating = \"NON-AGENTIVITY\"\n",
    "alternation_set = [\"man\", \"werden\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468f981-a93f-49d5-8919-583f087f9854",
   "metadata": {},
   "source": [
    "## Annotation\n",
    "\n",
    "Annotation is typically done in multiple sessions. Hence, after each instance that you have annotated you may decide to end the session in which case everything tagged so far is saved. When starting the next session, you will only be assigned the remaining instances, i.e., those cases that have not been annotated thus far.\n",
    "\n",
    "### Preparations\n",
    "\n",
    "The first step presupposes that the \"VACC\" notebook was executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b87357-b82c-44fa-9833-bc71ab257551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying the preprocessed corpus file into the folder \"Quantitative_Analysis/Annotated_datasets\"\n",
    "#a separate copy for annotation is deemed safer than modifying the persistence-tagged corpus \n",
    "source_file = \"../../../VACC/3_Persistence_tagged/Persistence_VACC_all.csv\"\n",
    "destination_directory = \"../../Annotated_datasets/\"\n",
    "\n",
    "destination_file = os.path.join(destination_directory, \"VACC.csv\")\n",
    "\n",
    "if not os.path.exists(destination_file):\n",
    "    shutil.copy2(source_file, destination_file)\n",
    "    print(\"File moved.\")\n",
    "else:\n",
    "    print(\"File already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28140fc-9e12-445d-b403-0a8418662afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the (copied) corpus file\n",
    "df = pd.read_csv(\"../../Annotated_datasets/VACC.csv\", sep=\",\", index_col=0)\n",
    "\n",
    "#lower-casing the lemma column, as the code below only checks for lower-case variants\n",
    "df.lemma = df.lemma.str.lower()\n",
    "\n",
    "#creating a column for saving annotation decisions, if it does not already exist\n",
    "if not alternating in df.columns:\n",
    "    df[alternating] = pd.NA\n",
    "\n",
    "#informing about how many alternating instances have already been tagged\n",
    "print(f\"Cases annotated as alternating: {len(df[df[alternating]=='yes'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed739fc-ddc6-462c-9f5d-b62a197b0bd2",
   "metadata": {},
   "source": [
    "### Annotation Tool\n",
    "\n",
    "In short, the tool below \n",
    "- informs you about the annotation scheme\n",
    "- tells you how many untagged instances you have got left\n",
    "- provides you with the next case to annotate, i.e., a potentially alternating lemma including its immediate context\n",
    "- displays an input field for deciding the current case according to the scheme\n",
    "- prompts you to confirm your decision and/or gives you the option to end the current session\n",
    "- searches for identical contexts prompting you whether the decision should be applied there as well\n",
    "\n",
    "Decisions are saved in `df_updated`. After each session, this DataFrame still needs to be saved externally. To start a new session, start by reading in the current version of \"../Annotated_datasets/VACC.csv\" under \"Preparations\" above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b8b1c4-821e-4bf0-98fd-8507282a2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotating\n",
    "df_updated = annotation.alternation_check(df, alternation_set, alternating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c277a7e-6fe3-40cf-8a24-256a08a51ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the updated DataFrame externally, overwriting the empty or part-annotated file\n",
    "df_updated.to_csv(\"../../Annotated_datasets/VACC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15373b89-49d3-4223-a1ed-366c4d18d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once all potentially alternating cases have been annotated, all other tokens of the DataFrame are additionally tagged as non-alternating\n",
    "if df_updated.loc[df_updated.lemma.isin(alternation_set), alternating].notna().all():\n",
    "    df_updated[alternating].fillna(value=\"no\", inplace=True)\n",
    "    df_updated.to_csv(\"../../Annotated_datasets/VACC.csv\")\n",
    "    print(\"Annotation is completed.\")\n",
    "else:\n",
    "    print(\"Annotation is not yet completed, rerun the tool above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846f564-d997-4bd6-9015-fd838e5938ed",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "See how many times each speaker used one of the alternating variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29adc520-3e8f-48d7-ad66-7aaee9ebf3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the annotated corpus, filtering, grouping and counting values\n",
    "df = pd.read_csv(\"../../Annotated_datasets/VACC.csv\", sep=\",\", index_col=0, na_filter=False)\n",
    "df[df[alternating] == \"yes\"].groupby(\"speaker\").lemma.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420319ba-64c8-40a3-86a6-613e1d2e933a",
   "metadata": {},
   "source": [
    "## Preparing DataFrame for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074782cb-9e6a-46a5-9b5e-8108170a9ebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading in the annotated corpus now including a column indicating where there was an opportunity (\"yes\") to choose a variant from the alternation set or not (\"no\")\n",
    "df = pd.read_csv(\"../../Annotated_datasets/VACC.csv\", index_col=0, na_filter=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b97a22-330e-4c15-900a-8776948c4a72",
   "metadata": {},
   "source": [
    "Below, the module `quantification` extracts or calculates all relevant variables for each choice context and saves the resulting DataFrame externally. The code for saving is commented out though as it would replace the file that was used for modelling in the thesis. As mentioned, said file is shared given its abstract nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218c4a6-3a33-4f75-af2f-7198f3be5079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating variation_sample, i.e., only annotated choice contexts along with relevant variables\n",
    "variation_sample = quantification.prepare_data_for_modeling(df, alternating, restrict=\"yes\", beta_variants=[\"man\", \"werden\"])\n",
    "#variation_sample.to_csv(f\"{alternating}_for_modelling_VACC.csv\")\n",
    "variation_sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvai",
   "language": "python",
   "name": "hvai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
