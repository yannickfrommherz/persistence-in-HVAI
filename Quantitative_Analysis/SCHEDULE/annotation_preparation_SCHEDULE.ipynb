{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9480e2b0-cc63-4cf2-866e-6006e9275af9",
   "metadata": {},
   "source": [
    "# SCHEDULE\n",
    "\n",
    "In this notebook, the preprocessed VACC corpus is annotated for the SCHEDULE alternation, i.e., all alternating instances of that alternation set are tagged in the data. Subsequently, a dataset is prepared for descriptive analysis, i.e., relevant variables (e.g., which variant was used in the previous slot?) from the tagged choice contexts are extracted or calculated. Further, the annotated instances are cross-tabulated and plots including a Sankey diagram are generated.\n",
    "\n",
    "As mentioned, the actual data used in the doctoral thesis needs to be requested from Ingo Siegert and subsequently preprocessed using the \"VACC\" notebook in the corresponding folder.\n",
    "\n",
    "However, the dummy dataset provided for the \"VACC\" notebook generates a dataset that can also be used to execute this very notebook. Note though that there are only very few instances of SCHEDULE in the dummy dataset (have a look at the DEZEMBER alternation instead).\n",
    "\n",
    "Refer to the relevant chapter in the doctoral thesis for further explanation of the steps below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145bdff-9eae-49c3-bfd4-5b7098210de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant modules\n",
    "import pandas as pd, sys, os, shutil, warnings, matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "#informing Python about a custom code directory and importing some of the modules from there\n",
    "sys.path.append(\"../../Code/\")\n",
    "import annotation, quantification, persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c32d2b8-df11-42a1-860d-f9a0ae123d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining name of the alternation set and establishing its variants\n",
    "alternating = \"SCHEDULE\"\n",
    "alternation_set = [\"erstellen\", \"eintragen\", \"tragen\", \"speichern\", \"hinzufügen\", \"fügen\", \"markieren\", \"planen\", \"vereinbaren\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e0446-667b-46a7-9266-ba5d18eab530",
   "metadata": {},
   "source": [
    "## Annotation\n",
    "\n",
    "Annotation is typically done in multiple sessions. Hence, after each instance that you have annotated you may decide to end the session in which case everything tagged so far is saved. When starting the next session, you will only be assigned the remaining instances, i.e., those cases that have not been annotated thus far.\n",
    "\n",
    "### Preparations\n",
    "\n",
    "The first step presupposes that the \"VACC\" notebook was executed, either using the actual data or the dummy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ea5a0-3b7b-45b7-be4a-377412a9b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying the preprocessed corpus file into the folder \"Quantitative_Analysis/Annotated_datasets\"\n",
    "#a separate copy for annotation is deemed safer than modifying the persistence-tagged corpus \n",
    "source_file = \"../../VACC/3_Persistence_tagged/Persistence_VACC_all.csv\"\n",
    "destination_directory = \"../Annotated_datasets/\"\n",
    "\n",
    "destination_file = os.path.join(destination_directory, \"VACC.csv\")\n",
    "\n",
    "if not os.path.exists(destination_file):\n",
    "    shutil.copy2(source_file, destination_file)\n",
    "    print(\"File moved.\")\n",
    "else:\n",
    "    print(\"File already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264c849-0aea-41ab-934e-8d7f68e68dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the (copied) corpus file\n",
    "df = pd.read_csv(\"../Annotated_datasets/VACC.csv\", sep=\",\", index_col=0)\n",
    "\n",
    "#lower-casing the lemma column, as the code below only checks for lower-case variants\n",
    "df.lemma = df.lemma.str.lower()\n",
    "\n",
    "#creating a column for saving annotation decisions, if it does not already exist\n",
    "if not alternating in df.columns:\n",
    "    df[alternating] = pd.NA\n",
    "\n",
    "#informing about how many alternating instances have already been tagged\n",
    "print(f\"Cases annotated as alternating: {len(df[df[alternating]=='yes'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a57d7c-a972-4fb4-bb3c-dbc5a3bbbd86",
   "metadata": {},
   "source": [
    "### Annotation tool\n",
    "\n",
    "In short, the tool below \n",
    "- informs you about the annotation scheme\n",
    "- tells you how many untagged instances you have got left\n",
    "- provides you with the next case to annotate, i.e., a potentially alternating lemma including its immediate context\n",
    "- displays an input field for deciding the current case according to the scheme\n",
    "- prompts you to confirm your decision and/or gives you the option to end the current session\n",
    "- searches for identical contexts prompting you whether the decision should be applied there as well\n",
    "\n",
    "Decisions are saved in `df_updated`. After each session, this DataFrame still needs to be saved externally. To start a new session, start by reading in the current version of \"../Annotated_datasets/VACC.csv\" under \"Preparations\" above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf9554-391b-4cc8-8ddb-3b002205ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotating\n",
    "df_updated = annotation.alternation_check(df, alternation_set, alternating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb13aac-4d3f-4f00-8c76-49eddd39e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the updated DataFrame externally, overwriting the empty or part-annotated file\n",
    "df_updated.to_csv(\"../Annotated_datasets/VACC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ffb02-eea2-4d81-8b26-a1322462abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once all potentially alternating cases have been annotated, all other tokens of the DataFrame are additionally tagged as non-alternating\n",
    "if df_updated.loc[df_updated.lemma.isin(alternation_set), alternating].notna().all():\n",
    "    df_updated[alternating].fillna(value=\"no\", inplace=True)\n",
    "    df_updated.to_csv(\"../Annotated_datasets/VACC.csv\")\n",
    "    print(\"Annotation is completed.\")\n",
    "else:\n",
    "    print(\"Annotation is not yet completed, rerun the tool above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c704cd-9539-4c40-9a91-6ad52595e5ca",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "See how many times each speaker used one of the alternating variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddeab12-3fab-44e0-b105-76a4aa78bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the annotated corpus, filtering, grouping and counting values\n",
    "df = pd.read_csv(\"../Annotated_datasets/VACC.csv\", sep=\",\", index_col=0, na_filter=False)\n",
    "df[df[alternating] == \"yes\"].groupby(\"speaker\").lemma.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d098c-c00f-470c-bef0-b307ae41d81a",
   "metadata": {},
   "source": [
    "## Preparing DataFrame for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b1a7f-bf86-4435-b3d5-4f06785f7ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading in the annotated corpus now including a column indicating where there was an opportunity (\"yes\") to choose a variant from the alternation set or not (\"no\")\n",
    "df = pd.read_csv(\"../Annotated_datasets/VACC.csv\", index_col=0, na_filter=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e322171-408f-4395-8a24-2cfa3f13a66f",
   "metadata": {},
   "source": [
    "Below, the function `prepare_data_for_modeling` extracts or calculates all relevant variables for each choice context and saves the resulting DataFrame externally. The code for saving is commented out though as it would replace the file that was used for modelling in the thesis. As mentioned, said file is shared given its abstract nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d0517-4b85-415b-9844-f72801ffbb73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating variation_sample, i.e., only annotated choice contexts along with relevant variables\n",
    "variation_sample = quantification.prepare_data_for_modeling(df, alternating, restrict=\"yes\")\n",
    "\n",
    "#normalising split verbs to their correct infinitive form\n",
    "normalising_dict = {\"tragen\": \"eintragen\", \"fügen\": \"hinzufügen\"}\n",
    "variation_sample.replace(normalising_dict, inplace=True)\n",
    "\n",
    "#update alternation_set\n",
    "alternation_set = [\"erstellen\", \"eintragen\", \"speichern\", \"hinzufügen\", \"markieren\", \"planen\", \"vereinbaren\"] \n",
    "\n",
    "#variation_sample.to_csv(f\"{alternating}_for_modelling.csv\")\n",
    "variation_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f077cf-e262-4e29-906c-26fb3e6255ca",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "### Cross-Tabulation\n",
    "\n",
    "Creating a table showing how often each variant in PREVIOUS was followed by the same or the other variant in CURRENT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127dead-89e4-40bf-8555-c11ae868f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(variation_sample.PREVIOUS, variation_sample.CURRENT)\n",
    "contingency_table[\"Total in PREVIOUS\"] = contingency_table.sum(axis=1)\n",
    "contingency_table.loc[\"Total in CURRENT\"] = contingency_table.sum(axis=0)\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0342ba-23e8-4f04-8da4-0f7ae069281f",
   "metadata": {},
   "source": [
    "### Sankey Diagram\n",
    "\n",
    "Creating a Sankey Diagram showing pairwise variant flow. This plot can only be generated using the actual data as there are no values to plot from the dummy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a980e-4a46-4958-a2ce-23119054e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantification.create_sankey_diagram(variation_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b35b5a3-6ec6-44a3-95b2-efa7f18f8953",
   "metadata": {},
   "source": [
    "### Distribution of Variants in PREVIOUS per Speaker\n",
    "\n",
    "Creating a plot showing the distribution of variants in PREVIOUS per speaker. This plot can only be generated using the actual data as there are no values to plot from the dummy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d9a6b-96d5-4e0b-8d36-f13a7313f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining plot and activating LaTex rendering\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=300) \n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "#editing speaker labels\n",
    "variation_sample.PREVIOUS_SPEAKER = variation_sample.PREVIOUS_SPEAKER.replace(\"A\", \"Voice assistant\")\n",
    "variation_sample.PREVIOUS_SPEAKER = variation_sample.PREVIOUS_SPEAKER.replace(\"S\", \"Human speaker\")\n",
    "variation_sample.PREVIOUS_SPEAKER = variation_sample.PREVIOUS_SPEAKER.replace(\"J\", \"Confederate\")\n",
    "\n",
    "#grouping by the previous speaker and counting values\n",
    "grouped = variation_sample.groupby(\"PREVIOUS_SPEAKER\").PREVIOUS.value_counts()\n",
    "grouped = grouped.unstack().fillna(0).T\n",
    "\n",
    "#plotting values\n",
    "grouped.plot(kind=\"bar\", ax=ax, colormap=\"Pastel1\", edgecolor=\"black\")\n",
    "\n",
    "#fine-tuning the plot\n",
    "ax.set_xticklabels([r'\\textit{' + label.get_text() + '}' for label in ax.get_xticklabels()])\n",
    "plt.ylabel(r\"Frequency\", fontsize=13)\n",
    "plt.xlabel(r\"Variant in \\textsc{previous}\", fontsize=13)\n",
    "plt.legend(title=r\"Speaker of \\textsc{previous}\", fontsize=12, title_fontsize=13)\n",
    "plt.xticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvai",
   "language": "python",
   "name": "hvai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
