{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e139bf92-1b13-41e9-88cb-a6857971520d",
   "metadata": {},
   "source": [
    "# VACW\n",
    "\n",
    "In this notebook all preprocessing steps for creating the final VACW corpus are run as well as the persistence tagging algorithm for the qualitative analysis. \n",
    "\n",
    "As mentioned, the actual data used in the doctoral thesis needs to be requested from Ingo Siegert. Once the actual data is available, save it in \"VACW/1_Corpus/Original_files/VACW.xlsx\".\n",
    "\n",
    "Have a look at the notebook for VACC if you want to see it executed using dummy data.\n",
    "\n",
    "Refer to the relevant chapters in the doctoral thesis for further explanation of the steps below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfd246-29f5-40ae-b866-af800e046123",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d43af6-ba5b-41e6-8967-fb91b38db8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant modules\n",
    "import pandas as pd, json, sys, os, warnings, re\n",
    "from tqdm import tqdm\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#informing Python about a custom code directory and importing some of the modules from there\n",
    "sys.path.append(\"../Code/\")\n",
    "import preprocessing, persistence, visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e60d81-2c89-4a9e-9278-eaaab5ad130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining corpus name \n",
    "#(some modules contain corpora-specific code, thus a variable with the corpus name is needed to ensure the right code is executed)\n",
    "which_corpus = \"VACW\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4224c2-345c-4df8-9984-cfd16f875bf5",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Creating One CSV File\n",
    "\n",
    "The following code creates *one* csv file containing all turns from all interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ef732-7584-4413-8c80-c83364f690a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.file_creator_vacw(f\"1_Corpus/Original_files/{which_corpus}.xlsx\",\n",
    "                                f\"1_Corpus/Corpus_{which_corpus}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ea9f3-9f82-458b-864d-e0dc49d4efe3",
   "metadata": {},
   "source": [
    "### Tokenising and Lemmatising Data \n",
    "\n",
    "Note that, as explained in the thesis, POS-tagging was initially also performed. As its output was not used this step is disregarded here.\n",
    "\n",
    "Lemmatisation was performed with both TreeTagger and RNNTagger. As explained in the thesis, the RNNTagger's output proved to be most reliable. To execute the following steps you need to download the [RNNTagger](https://www.cis.lmu.de/~schmid/tools/RNNTagger/) and follow the installation steps indicated there. \n",
    "\n",
    "The RNNTagger expects a simple file with one token per row. To be able to remap tagged tokens to their corresponding metadata (which turn they belong to, by which speaker etc.), during tokenisation below, an additional list (`tokens_for_remapping`) is outputted which contains the same tokens as well as a turn boundary marker. This marker enables remapping the tokens to their respective turn, once they have been tagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f40be3-433b-4faf-87bb-537d9a50dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenising using custom code for later token remapping\n",
    "tokens_for_remapping = preprocessing.tokenise(f\"1_Corpus/Corpus_{which_corpus}.csv\", \n",
    "                                              \"2_Preprocessed/Files/txt_file_for_tagger.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124b791-a700-460c-bafc-5edd58f26ec3",
   "metadata": {},
   "source": [
    "Next, run the following lines in your command line inside the conda environment, replacing \"rnntagger_path\" with the absolute path to your RNNTagger directory, \"txt_file_for_tagger.txt\" with the absolute path to said file (created in the cell above) and \"output\" with the absolute path leading to a new file called \"VACW/2_Preprocessed/Files/RNN_tagged.txt\" (i.e., complement that path based on where you stored the entire repository on your computer). Execute the middle line only if permission errors occur."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c51b339e-b46c-458c-837f-8f9f0db6d561",
   "metadata": {},
   "source": [
    "cd rnntagger_path\n",
    "chmod -R +x . \n",
    "cmd/rnn-tagger-german.sh txt_file_for_tagger.txt > output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96b9ed-dd6c-4990-8e80-3a9226d20527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remapping tagged tokens to their respective turn\n",
    "preprocessing.remap(f\"1_Corpus/Corpus_{which_corpus}.csv\", #corpus\n",
    "                    f\"2_Preprocessed/Files/RNN_tagged.txt\", #tagger output\n",
    "                    tokens_for_remapping, #needed for remapping tagger output to corpus\n",
    "                    f\"2_Preprocessed/RNN_{which_corpus}_unigrams.csv\", #destination of remapped corpus\n",
    "                    which_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5bd09-8fd3-4487-bfa1-305e97f59a27",
   "metadata": {},
   "source": [
    "Note that, as explained in the thesis, manual lemma correction was performed at this point. Hence, when running this notebook with the actual data, it will eventually differ from the data used in the study as this manual step cannot be replicated here.\n",
    "\n",
    "### Creating Lemma Bi-, Tri-, and Quadrigrams\n",
    "\n",
    "The following code creates lemma n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7321f01-a4e4-482b-b9b4-d5c3fae365ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.ngrammer(f\"2_Preprocessed/RNN_{which_corpus}_unigrams.csv\", which_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b293b95-009b-4bb5-8cf1-c0255abbda87",
   "metadata": {},
   "source": [
    "Preprocessing of the corpus is now done. Note again that even if you ran the code with the actual data, it will to some extent be different from the data used in the thesis due to non-replicable manual steps (see above). \n",
    "\n",
    "For the quantitative analysis see separate notebooks in the directory \"Quantitative_analysis\". This code is in separate notebooks as some quantitative analyses extend beyond one single corpus and are thus organised with regard to alternation sets. Also, a different programming language (R) is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3f842-e3ad-4971-ac6c-db4f5478c046",
   "metadata": {},
   "source": [
    "## Persistence Tagging for the Qualitative Analysis\n",
    "\n",
    "As mentioned in the thesis, the persistence tagging algorithm can be used to tag cases of persistence on multiple levels such as lemmata, POS-tags etc. However, the qualitative analysis in the thesis relied solely on lemma-based tagging. This is defined in the following cell, along with stop lemmata and lemmata from the instructions, both of which will be excluded from tagging. \n",
    "\n",
    "Also note that `tagger` can be used to tag, e.g., cases of persistence from the human speaker to the voice assistant (i.e., tagging cases of quasi-persistence). For that, pass different values for the corresponding arguments than the default ones which implement allo-persistence from voice assistant to human speaker. \n",
    "\n",
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9fba3-28af-4fda-bbf6-8541ad1f2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\"lemma\"] #defining level to tag on \n",
    "\n",
    "stoplemmas = ['an', 'der', 'ein', 'es', 'f√ºr', 'haben', 'ich', 'in', 'mit', \n",
    "              'nicht', 'oder', 'sein', 'um', 'und', 'von', 'werden', 'zu'] #defining stopwords to exclude from tagging\n",
    "\n",
    "#reading and defining instructions (in VACW, these are only filtered out when tagging unigrams)\n",
    "with open(\"Instructions/lemmatised_quiz_questions.txt\") as f:\n",
    "    instructions = [line.strip(\"\\n,'' \") for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446c0b6-6b30-442b-96f9-4b6c67ced6b4",
   "metadata": {},
   "source": [
    "### Tagging\n",
    "\n",
    "#### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a132ee-60df-4db2-aedd-3a6df42d5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading unigram corpus\n",
    "corpus = pd.read_csv(f\"2_Preprocessed/RNN_{which_corpus}_unigrams.csv\", sep=\",\", index_col=0, na_filter=False)\n",
    "\n",
    "#passing unigram corpus to persistence tagger while specifying levels, output destination, instructions and stoplemmas\n",
    "persistence.tagger(corpus, which_corpus, levels, f\"3_Persistence_tagged/single_ngrams/Persistence_{which_corpus}_unigrams.csv\", instructions, stoplemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52556c-5809-4531-bb9c-3d096f7efd6e",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6162d-44b6-4fd3-9034-f71397f827c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading bigram corpus\n",
    "corpus = pd.read_csv(f\"2_Preprocessed/RNN_{which_corpus}_bigrams.csv\", sep=\",\", index_col=0, na_filter=False)\n",
    "\n",
    "#passing bigram corpus to persistence tagger while specifying levels, output destination\n",
    "persistence.tagger(corpus, which_corpus, levels, f\"3_Persistence_tagged/single_ngrams/Persistence_{which_corpus}_bigrams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87e687-5d96-4e53-b447-7376b001eab0",
   "metadata": {},
   "source": [
    "#### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febebbc3-16cd-4a0c-9e42-08147b6f0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading trigram corpus\n",
    "corpus = pd.read_csv(f\"2_Preprocessed/RNN_{which_corpus}_trigrams.csv\", sep=\",\", index_col=0, na_filter=False)\n",
    "\n",
    "#passing trigram corpus to persistence tagger while specifying levels, output destination\n",
    "persistence.tagger(corpus, which_corpus, levels, f\"3_Persistence_tagged/single_ngrams/Persistence_{which_corpus}_trigrams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9263b-c136-47e2-84a7-10d1669d777b",
   "metadata": {},
   "source": [
    "#### Quadrigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41746b31-7726-47c7-8d88-92fe82582b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading quadrigram corpus\n",
    "corpus = pd.read_csv(f\"2_Preprocessed/RNN_{which_corpus}_quadrigrams.csv\", sep=\",\", index_col=0, na_filter=False)\n",
    "\n",
    "#passing quadrigram corpus to persistence tagger while specifying levels, output destination\n",
    "persistence.tagger(corpus, which_corpus, levels, f\"3_Persistence_tagged/single_ngrams/Persistence_{which_corpus}_quadrigrams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844a8cb-e118-47e6-938f-c77f64ea056b",
   "metadata": {},
   "source": [
    "For simplicity, the following code combines all n-gram levels into one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d477bd9-5712-459e-a3a9-cbdf4b59e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence.combiner(\"3_Persistence_tagged/single_ngrams\", f\"3_Persistence_tagged/Persistence_{which_corpus}_all.csv\", which_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0a2bc-eba2-4026-9d3e-fcd8ecf4f43e",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "The following code visualises tagged cases of persistence on all n-grams levels in HTML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29f4e3-791f-4c33-a2d2-53a459d5bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation.lemma(which_corpus, \"3_Persistence_tagged\", \"3_Persistence_tagged/visualisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d4a679-b37b-44ad-aaae-43884a295707",
   "metadata": {},
   "source": [
    "### Inspecting Frequent Cases of Persistence\n",
    "\n",
    "The following code outputs frequent cases of persistence for each n-gram level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda8f5e-4fde-4788-90b3-12a1e7b787d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualisation.inspect(levels = [\"lemma\"], #further levels such as POS-tags could be supplied if tagging was performed on that level\n",
    "                      ngrams = [\"unigrams\", \"bigrams\", \"trigrams\", \"quadrigrams\"], \n",
    "                      threshold = 0, \n",
    "                      which_corpus =  which_corpus, \n",
    "                      path = \"3_Persistence_tagged/single_ngrams\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Persistence in HVAI",
   "language": "python",
   "name": "hvai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
