{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6443180-5338-4314-be7b-adab19853da6",
   "metadata": {},
   "source": [
    "# DEZEMBER\n",
    "\n",
    "In this notebook, the preprocessed VACC corpus is annotated for the DEZEMBER alternation, i.e., all alternating instances of \"dezember\" and \"zwölf\" are tagged in the data. Subsequently, a dataset is prepared for modelling, i.e., all relevant variables (e.g., which variant was used in the previous slot?) from the tagged choice contexts are extracted or calculated. Further, the annotated instances are cross-tabulated and a switch rate plot is generated for the Descriptive Statistics part in the thesis.\n",
    "\n",
    "As mentioned, the actual data used in the doctoral thesis needs to be requested from Ingo Siegert and subsequently preprocessed using the \"VACC\" notebook in the corresponding folder.\n",
    "\n",
    "However, the dummy dataset provided for the \"VACC\" notebook generates a dataset that can also be used to execute this very notebook. \n",
    "\n",
    "Refer to the relevant chapter in the doctoral thesis for further explanation of the steps below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe45b0-2d3b-4ecc-aba1-6f128fd1077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant modules\n",
    "import pandas as pd, sys, os, shutil, warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "#informing Python about a custom code directory and importing some of the modules from there\n",
    "sys.path.append(\"../../Code/\")\n",
    "import annotation, quantification, persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc4b277-3d4b-49af-aed7-e3196fad8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining name of the alternation set and establishing its variants\n",
    "alternating = \"DEZEMBER\"\n",
    "alternation_set = [\"dezember\", \"zwölf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e37be5a-9c3f-4eea-9d70-20a01d6e3bf6",
   "metadata": {},
   "source": [
    "## Annotation\n",
    "\n",
    "Annotation is typically done in multiple sessions. Hence, after each instance that you have annotated you may decide to end the session in which case everything tagged so far is saved. When starting the next session, you will only be assigned the remaining instances, i.e., those cases that have not been annotated thus far.\n",
    "\n",
    "### Preparations\n",
    "\n",
    "The first step presupposes that the \"VACC\" notebook was executed, either using the actual data or the dummy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ea5a0-3b7b-45b7-be4a-377412a9b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying the preprocessed corpus file into the folder \"Quantitative_analysis/Annotated_datasets\"\n",
    "#a separate copy for annotation is deemed safer than modifying the persistence-tagged corpus \n",
    "source_file = \"../../VACC/3_Persistence_tagged/Persistence_VACC_all.csv\"\n",
    "destination_directory = \"../Annotated_datasets/\"\n",
    "\n",
    "destination_file = os.path.join(destination_directory, \"VACC.csv\")\n",
    "\n",
    "if not os.path.exists(destination_file):\n",
    "    shutil.copy2(source_file, destination_file)\n",
    "    print(\"File moved.\")\n",
    "else:\n",
    "    print(\"File already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264c849-0aea-41ab-934e-8d7f68e68dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the (copied) corpus file\n",
    "df = pd.read_csv(\"../Annotated_datasets/VACC.csv\", sep=\",\", index_col=0)\n",
    "\n",
    "#lower-casing the lemma column, as the code below only checks for lower-case variants\n",
    "df.lemma = df.lemma.str.lower()\n",
    "\n",
    "#creating a column for saving annotation decisions, if it does not already exist\n",
    "if not alternating in df.columns:\n",
    "    df[alternating] = pd.NA\n",
    "\n",
    "#informing about how many alternating instances have already been tagged\n",
    "print(f\"Cases annotated as alternating: {len(df[df[alternating]=='yes'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366f0f0-d181-42a1-b61f-b5898af3647d",
   "metadata": {},
   "source": [
    "### Annotation Tool\n",
    "\n",
    "In short, the tool below \n",
    "- informs you about the annotation scheme\n",
    "- tells you how many untagged instances you have got left\n",
    "- provides you with the next case to annotate, i.e., a potentially alternating lemma including its immediate context\n",
    "- displays an input field for deciding the current case according to the scheme\n",
    "- prompts you to confirm your decision and/or gives you the option to end the current session\n",
    "- searches for identical contexts prompting you whether the decision should be applied there as well\n",
    "\n",
    "Decisions are saved in `df_updated`. After each session, this DataFrame still needs to be saved externally. To start a new session, start by reading in the current version of \"../Annotated_datasets/VACC.csv\" under \"Preparations\" above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf9554-391b-4cc8-8ddb-3b002205ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotating\n",
    "df_updated = annotation.alternation_check(df, alternation_set, alternating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb13aac-4d3f-4f00-8c76-49eddd39e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the updated DataFrame externally, overwriting the empty or part-annotated file\n",
    "df_updated.to_csv(\"../Annotated_datasets/VACC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ffb02-eea2-4d81-8b26-a1322462abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once all potentially alternating cases have been annotated, all other tokens of the DataFrame are additionally tagged as non-alternating\n",
    "if df_updated.loc[df_updated.lemma.isin(alternation_set), alternating].notna().all():\n",
    "    df_updated[alternating].fillna(value=\"no\", inplace=True)\n",
    "    df_updated.to_csv(\"../Annotated_datasets/VACC.csv\")\n",
    "    print(\"Annotation is completed.\")\n",
    "else:\n",
    "    print(\"Annotation is not yet completed, rerun the tool above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc845860-14f7-45ca-9d21-4ad9e2acd5f5",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "See how many times each speaker used one of the alternating variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddeab12-3fab-44e0-b105-76a4aa78bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the annotated corpus, filtering, grouping and counting values\n",
    "df = pd.read_csv(\"../Annotated_datasets/VACC.csv\", sep=\",\", index_col=0, na_filter=False)\n",
    "df[df[alternating] == \"yes\"].groupby(\"speaker\").lemma.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9ceef-058b-4307-9244-3d7fadf4ae5d",
   "metadata": {},
   "source": [
    "## Preparing DataFrame for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ed9f0-f9ed-4d12-989d-f4e6c96fed36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading in the annotated corpus now including a column indicating where there was an opportunity (\"yes\") to choose a variant from the alternation set or not (\"no\")\n",
    "df = pd.read_csv(\"../Annotated_datasets/VACC.csv\", index_col=0, na_filter=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6fa979-5a73-4f3f-9786-7b01965e856e",
   "metadata": {},
   "source": [
    "Below, the function `prepare_data_for_modeling` extracts or calculates all relevant variables for each choice context and saves the resulting DataFrame externally. This code only works properly if annotation has been completed. The code for saving is commented out though as it would replace the file that was used for modelling in the thesis. As mentioned, said file is shared given its abstract nature.\n",
    "\n",
    "In the model for this alternation set, a variable for quasi-persistence on the part of the voice assistant was included. Before running `quantification`, information on instances of quasi-persistence need to be extracted from the relevant files and added to `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4794b4-3d20-4db7-a20e-b40d9d818b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding information on lexical quasi-persistence to df, by reading in the combined file...\n",
    "df_quasi_p = pd.read_csv(\"../../VACC/3_Persistence_tagged/Quasi_persistence_VACC_all.csv\", na_filter=False, sep=\",\")\n",
    "#... and summarising all kinds of lexical quasi-persistence, i.e., writing True in new column, if any lexical SPP was produced by the voice assistant\n",
    "df[\"quasi_persistence\"] = df_quasi_p[[\"persistence_unigrams_lemma\", \"persistence_bigrams_lemma\", \"persistence_trigrams_lemma\", \"persistence_quadrigrams_lemma\"]].applymap(lambda x: str(x).startswith(\"SPP\")).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ba7bc-3d50-4e12-b4a7-e71ddedd072e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating variation_sample, i.e., only annotated choice contexts along with relevant variables\n",
    "variation_sample = quantification.prepare_data_for_modeling(df, alternating, include_quasi_p=True, restrict=\"yes\", beta_variants=[\"zwölf\", \"dezember\"])\n",
    "\n",
    "#saving externally (not done, as it would overwrite the actual data used in the thesis which is shared in this repository due to its abstract nature)\n",
    "#variation_sample.to_csv(f\"{alternating}_for_modelling.csv\")\n",
    "variation_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82884d05-a75e-48ad-89fc-9d2d11d922c3",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "### Cross-Tabulation\n",
    "\n",
    "Creating a table showing how often each variant in PREVIOUS was followed by the same or the other variant in CURRENT, using the data annotated and prepared above. Again, both this code and the following ones only work if annotation has been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0411cb-22c6-4a70-8bd2-fc38af0ac813",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(variation_sample.PREVIOUS, variation_sample.CURRENT)\n",
    "contingency_table[\"Total in PREVIOUS\"] = contingency_table.sum(axis=1)\n",
    "contingency_table.loc[\"Total in CURRENT\"] = contingency_table.sum(axis=0)\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac1f2a-ebd0-4f77-ba93-628453b516c1",
   "metadata": {},
   "source": [
    "### Switch Rate Plot\n",
    "\n",
    "Finally, a switch rate plot is generated. Note that for calculating variant shares, the entire corpus is also needed. Make sure to combine the entire corpus and the variation sample of either the dummy dataset *or* the actual data, ensuring you do not mix the two.\n",
    "\n",
    "Given its size, when using the dummy dataset, only very few dots will be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea312239-6d02-4dcf-985f-dd7752eba845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in entire corpus (needed for calculating variant shares) as well as the variation sample\n",
    "df = pd.read_csv(\"../Annotated_datasets/VACC.csv\", na_filter=False, sep=\",\", index_col=0)\n",
    "\n",
    "#defining output path for the plot\n",
    "path = \"switch_rate_plot_DEZEMBER.png\"\n",
    "\n",
    "#generating plot\n",
    "quantification.plot_switch_rate_over_variant_proportions(df, variation_sample, alternation_set, alternating, save_to=path, DEZEMBER=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Persistence in HVAI",
   "language": "python",
   "name": "hvai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
