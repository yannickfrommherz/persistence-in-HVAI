{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e139bf92-1b13-41e9-88cb-a6857971520d",
   "metadata": {},
   "source": [
    "# VACC\n",
    "\n",
    "In this notebook all preprocessing steps for creating the final VACC corpus are run as well as the persistence tagging algorithm for the qualitative analysis. \n",
    "\n",
    "A dummy dataset is provided for the code to be executable. Make sure to replace it with the actual data to replicate the corpus used in the doctoral thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfd246-29f5-40ae-b866-af800e046123",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19d43af6-ba5b-41e6-8967-fb91b38db8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading modules.\n"
     ]
    }
   ],
   "source": [
    "#import relevant modules\n",
    "\n",
    "import pandas as pd, json, sys, os, warnings, re\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "sys.path.append(\"../Code/\")\n",
    "\n",
    "if \"run_before\" not in locals():\n",
    "    print(\"Importing modules for the first time.\")\n",
    "    import preprocessing, persistence, combination, visualisation\n",
    "    run_before = \"yes\"\n",
    "else:\n",
    "    print(\"Reloading modules.\")\n",
    "    reload(preprocessing)\n",
    "    reload(persistence)\n",
    "    reload(combination)\n",
    "    reload(visualisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3f7202-1393-4f7f-8c32-8ae0a4f6d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define corpus name \n",
    "#(some modules contain corpora-specific code, thus a variable with the corpus name is needed\n",
    "#to ensure the right code is executed)\n",
    "which_corpus = \"VACC\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4224c2-345c-4df8-9984-cfd16f875bf5",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Creating one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcd29a5-f672-47f8-90fa-19deb0a545a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to folders with transcripts and speaker list (who made which utterance)\n",
    "root_transcripts = f\"1_Corpus/Original_files/Fertige_Transkripte/\"\n",
    "root_speakers = f\"1_Corpus/Original_files/Fertige_Utterances/\"\n",
    "output_destination = f\"1_Corpus/Corpus_{which_corpus}.csv\"\n",
    "\n",
    "preprocessing.file_creator_vacc(root_transcripts, root_speakers, output_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268683eb-fbb0-4bdb-bbe8-2410a8adf45e",
   "metadata": {},
   "source": [
    "### Merging same-speaker turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb4955f-0bbd-4303-a298-60f5a1ff5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"1_Corpus/Corpus_{which_corpus}.csv\"\n",
    "output_destination = f\"1_Corpus/Corpus_merged_turns_{which_corpus}.csv\"\n",
    "    \n",
    "preprocessing.turn_merger(file, output_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd85f0-6aa7-4319-aa30-62808f2dc5f5",
   "metadata": {},
   "source": [
    "Note that, as explained in the thesis, manual unmerging was performed in certain cases. Hence, when running this notebook with the actual data, it will eventually differ slightly from the data used in the study as this manual step as well as the manual lemma correction step mentioned below cannot be reproduced here.\n",
    "\n",
    "### Tokenising and lemmatising data \n",
    "\n",
    "Note that, as explained in the thesis, POS-tagging was initially also performed, but as its output was not used, this step is disregarded here.\n",
    "\n",
    "This step was performed with both TreeTagger and RNNTagger. As explained in the thesis, the RNNTagger's output proved to be most reliable. \n",
    "\n",
    "To execute the following steps you need to download the [RNNTagger](https://www.cis.lmu.de/~schmid/tools/RNNTagger/) and follow the installation steps indicated there. \n",
    "\n",
    "To be able to remap tagged tokens to the corresponding metadata (which turn they belong to, by which speaker etc.), tokenisation is performed using custom code. The following function both creates a tokenised file for tagging as well as `tokens_for_remapping` which contains the same tokens as well as an additional turn boundary marker that enables remapping the tokens to their respective turn, once they have been tagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1474743-eccb-41be-af60-ecf87db77aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_for_remapping = preprocessing.tokenise(f\"1_Corpus/Corpus_merged_turns_{which_corpus}.csv\", \n",
    "                                    \"2_Preprocessed/Files/txt_file_for_tagger.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c86358-c4c1-47f5-a7c4-c8b205416ffa",
   "metadata": {},
   "source": [
    "Next, run the following code in your command line, replacing \"rnntagger_path\" with the absolute path to your RNNTagger directory, \"txt_file_for_tagger.txt\" with the absolute path to said file (created in the cell above) and \"output\" with the absolute path leading to a new file called \"VACC/2_Preprocessed/Files/RNN_tagged.txt\" (i.e., complement that path based on where you stored the entire repository on your computer)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb2e6ea8-a447-4f2e-ba4b-b6d53c33b0fe",
   "metadata": {},
   "source": [
    "cd rnntagger_path\n",
    "cmd/rnn-tagger-german.sh txt_file_for_tagger.txt > VACC/2_Preprocessed/Files/RNN_tagged.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8729c47a-d746-4f31-8356-392d3ff4e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.remap(f\"1_Corpus/Corpus_merged_turns_{which_corpus}.csv\", #corpus\n",
    "                    f\"2_Preprocessed/Files/RNN_tagged.txt\", #tagger output\n",
    "                    tokens_for_remapping, #needed for remapping tagger output to corpus\n",
    "                    f\"2_Preprocessed/RNN_{which_corpus}_unigrams.csv\", #destination of remapped corpus\n",
    "                    which_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef32d7-3610-4f9d-b4e2-694062768559",
   "metadata": {},
   "source": [
    "Note that, as explained in the thesis, manual lemma correction was performed at this point. \n",
    "\n",
    "### Creating lemma bi-, tri-, and quadrigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a42d96fc-fb9e-410f-88e5-295dde47a6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams\n",
      "trigrams\n",
      "quadrigrams\n"
     ]
    }
   ],
   "source": [
    "preprocessing.ngrammer(f\"2_Preprocessed/RNN_{which_corpus}_unigrams.csv\", which_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414814c4-ac0c-4bf2-a8aa-30aebe2bc169",
   "metadata": {},
   "source": [
    "Preprocessing of the corpus is now done. Note again that even if you ran the code with the actual data, it will be slightly different from the data used in the thesis due to non-replicable manual steps (see above). \n",
    "\n",
    "For the quantitative analysis see separate notebooks in the directory \"Quantitative_Analysis\". This code is in separate notebooks as some quantitative analyses extend beyond one single corpus and are thus organised with regard to alternation sets. Also, a different programming language (R) is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed2dd3-5400-4ece-bdf6-91804d6df5b6",
   "metadata": {},
   "source": [
    "## Persistence Tagging for Qualitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d524c4b-5160-4dc5-8a2d-0f0c1b75ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging (only for allo-persistence)\n",
    "# visualising (change module name)\n",
    "# inspect frequent persistent n-grams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvai",
   "language": "python",
   "name": "hvai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
